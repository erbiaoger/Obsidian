# 卷积神经网络概述

[TOC]

## 1. 神经元神经元

是人工神经网络的基本处理单元，一般是多输入单输出的单元，其结构模型如下

![https://raw.githubusercontent.com/erbiaoger/PicGo/main/img202209031156819.png](https://raw.githubusercontent.com/erbiaoger/PicGo/main/img202209031156819.png)

其中，$x_i$ 表示输入信号，$n$ 个输入信号同时输入神经元 $j$ 。$\omega_{ij}$ 表示输入信号 $x_i$ 与神经元 $j$ 连接的权重值，$b_j$ 表示神经元的内部状态即偏置值，$y_j$ 为神经元的输出。输入与输出之间的对应关系可用下式表示：

$$y_j = f(b_j + \sum_{i=1}^n(x_i*\omega_{ij})) \tag{1}$$

$f(\cdot)$ 为激励函数，其选择可以有很多种，可以是……

## 2.2 多层感知器

多层感知器(Multilayer Perceptron，MLP)是 由输入层、隐含层(一层或者多层)及输出层构成 的神经网络模型，它可以解决单层感知器不能解决 的线性不可分问题。图 2 是含有 2 个隐含层的多层 感知器网络拓扑结构图。

![](https://raw.githubusercontent.com/erbiaoger/PicGo/main/img202209031227481.png)

输入层神经元接收输入信号，隐含层和输出层 的每一个神经元与之相邻层的所有神经元连接，即 全连接，同一层的神经元间不相连。图 2 中，有箭头的线段表示神经元间的连接和信号传输的方向， 且每个连接都有一个连接权值。隐含层和输出层中 每一个神经元的输入为前一层所有神经元输出值的加权和。假设 $x_m^l$ 是MLP中第 $m$ 个神经元的输入值， $y_m^l$ 和 $b_m^l$ 分别为该神经元输出值和偏置值，$\omega_{im}^{l-1}$ 为该神经元与第 $l-1$ 层第 $i$ 个神经元的连接权值，则有：

$$x_m^l =	b_m^l + \sum_{i=1}^k \omega_{im}^{l-1} * y_i^{l-1} \tag{2}$$

$$y_m^l = f(x_m^l) \tag{3}$$

当多层感知器用于分类时，其输入神经元个数 为输入信号的维数，输出神经元个数为类别数，隐 含层个数及隐层神经元个数视具体情况而定。但在 实际应用中，由于受到参数学习效率影响，一般使 用不超过 3 层的浅层模型。BP 算法可分为两个阶段:前向传播和后向传播，其后向传播始于 MLP 的输出层。以图 2 为例，则损失函数为: